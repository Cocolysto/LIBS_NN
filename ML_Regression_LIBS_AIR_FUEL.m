% Solve an Input-Output Fitting problem with a Neural Network for a
% calibration dataset
% Script partially generated by Neural Fitting app
% Created 26-Oct-2023 15:47:09
% Edited 21/11/2023 18h07 by Nuno Rocha, UCL
%
% Start by importing the dataset
% The relevant data is found in "Bulk_AIR_FUEL" and the labels in "Bulk_AIR_FUEL_variables"

% Pick the relevant data to feed the network
% Data: Broadband intensities of C, N and H (rows: 31, 32, 33)
% Labels: CH4% and Z (rows: 1, 40)

load('LIBS_JB_Calibration_20240115.mat')
x = [Bulk_AIR_FUEL(31, :)./Bulk_AIR_FUEL(33, :); Bulk_AIR_FUEL(33, :)./Bulk_AIR_FUEL(32, :)];  % is the data: bbC/bbH, bbH/bbN
t = Bulk_AIR_FUEL([1, 40], :);  % are the labels: CH4%, Z

% Choose a Training Function
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainrp';  % Training algorythm

% Create a Fitting Network
hiddenLayerSize = 5;
net = fitnet(hiddenLayerSize, trainFcn);

% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
net.input.processFcns = {'removeconstantrows','mapminmax'};
net.output.processFcns = {'removeconstantrows','mapminmax'};

% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivision
net.divideFcn = 'dividerand';  % Divide data randomly
net.divideMode = 'sample';  % Divide up every sample
net.divideParam.trainRatio = 70/100;
net.divideParam.valRatio = 20/100;
net.divideParam.testRatio = 10/100;

% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'mse';  % Mean Squared Error

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    'plotregression', 'plotfit'};

% Train the Network
net.trainParam.showWindow = 0; 
[net,tr] = train(net,x,t);

% Test the Network
y = net(x);
e = gsubtract(t,y);
performance = perform(net,t,y);

% Recalculate Training, Validation and Test Performance
trainTargets = t .* tr.trainMask{1};
valTargets = t .* tr.valMask{1};
testTargets = t .* tr.testMask{1};
trainPerformance = perform(net,trainTargets,y);
valPerformance = perform(net,valTargets,y);
testPerformance = perform(net,testTargets,y);

% View the Network
% view(net)

% Plots
% Uncomment these lines to enable various plots.
figure, plotperform(tr)
figure, plottrainstate(tr)
figure, ploterrhist(e)
figure, plotregression(t,CH4_Z_NN)
figure, plotfit(net,x,t)


% Load the polynomial models for C/H and H/N curves
load('CH_polyModel.mat', 'CH_fit_poly2')
load('Z_polyModel.mat', 'custom_AIR_fit_Z')

% % Verify performance: Scaled Conjugate Gradient
% CH4_Z_NN = net(x);
CH4_Z_NN = NN2_5_trainrp(x);
subplot(1, 2, 1), plot3(x(1, :), x(2, :), [CH4_Z_NN(1, :); Bulk_AIR_FUEL(1, :)], '*'), xlabel('C/H'), ylabel('H/N'), zlabel('CH_4')
legend({'Estimated', 'Measured'}), title(sprintf('Hidden layer size: %i, Training: %s', hiddenLayerSize, trainFcn))
subplot(1, 2, 2), plot3(x(1, :), x(2, :), [CH4_Z_NN(2, :); Bulk_AIR_FUEL(40, :)], '*'), xlabel('C/H'), ylabel('H/N'), zlabel('Z')
legend({'Estimated', 'Measured'}), title(sprintf('Hidden layer size: %i, Training: %s', hiddenLayerSize, trainFcn))


% 3D Plots of Machine Learning Regressions for estimating CH4 and Z
% CH4
f5 = figure('Position', [2200, 250, 700, 650]);
H1 = axes(f5, 'FontSize', 12, 'TickLabelInterpreter','latex');
e = plot3(H1, x(1, :), x(2, :), [CH4_Z_NN(1, :); Bulk_AIR_FUEL(1, :)], '*');

% Axes and title
xlim([-.0005, .02]), xticks(0:.004:.02), xlabel('$C_{BB}/H_{BB}$', 'Interpreter','Latex', 'FontSize', 12);
ylim([2, 12]), yticks(2:2:12), ylabel('$H_{BB}/N_{BB}$', 'Interpreter','Latex', 'FontSize', 12);
zlim([-10, 110]), zticks(0:20:100), zlabel('$CH_4$\%', 'Interpreter','Latex', 'FontSize', 12);
legend({'Estimated', 'Measured'}, 'Interpreter','Latex', 'FontSize', 12, Location="northwest")
title({'ML Regression (Neural Network) for $CH_4$\%',...
    sprintf('Hidden layer size: %i, Training algorythm: %s, $R^2$=%.4f', hiddenLayerSize, trainFcn, .9916)},...
    'Interpreter','latex', 'FontSize',13.2)


% 3D Plots of Machine Learning Regressions for estimating CH4 and Z
% Z
f5 = figure('Position', [2200, 250, 700, 650]);
H1 = axes(f5, 'FontSize', 12, 'TickLabelInterpreter','latex');
e = plot3(H1, x(1, :), x(2, :), [CH4_Z_NN(2, :); Bulk_AIR_FUEL(40, :)], '*');

% Axes and title
xlim([-.0005, .02]), xticks(0:.004:.02), xlabel('$C_{BB}/H_{BB}$', 'Interpreter','Latex', 'FontSize', 12);
ylim([2, 12]), yticks(2:2:12), ylabel('$H_{BB}/N_{BB}$', 'Interpreter','Latex', 'FontSize', 12);
zlim([0, .12]), zticks(0:.02:.12), zlabel('$Z$', 'Interpreter','Latex', 'FontSize', 12);
legend({'Estimated', 'Measured'}, 'Interpreter','Latex', 'FontSize', 12, Location="northwest")
title({'ML Regression (Neural Network) for $Z$',...
    sprintf('Hidden layer size: %i, Training algorythm: %s, $R^2$=%.4f', hiddenLayerSize, trainFcn, .9916)},...
    'Interpreter','latex', 'FontSize',13.2)








% CH4_EST = feval(CH_fit_poly2, Bulk_AIR_FUEL(16, :));
% figure
% subplot(1, 3, 1)
% plot(custom_AIR_fit_Z, [CH4_Z_NN(1, :)', Bulk_AIR_FUEL(12, :)'], CH4_Z_NN(2, :)'), title(sprintf('Estimated NN 3:%i:2', hiddenLayerSize))
% alpha(0.5), xlim([0, 100]), ylim([0, 8]), zlim([0, .1])
% xlabel('$x - CH_4$\%', 'Interpreter', 'latex'); ylabel('$y - H/N$', 'Interpreter', 'latex'); zlabel('$z - Z$', 'Interpreter', 'latex')
% subplot(1, 3, 2)
% plot(custom_AIR_fit_Z, [CH4_EST, Bulk_AIR_FUEL(12, :)'],...
%     feval(custom_AIR_fit_Z, [CH4_EST, Bulk_AIR_FUEL(12, :)'])), title('Estimated Poly3')
% alpha(0.5), xlim([0, 100]), ylim([0, 8]), zlim([0, .1])
% xlabel('$x - CH_4$\%', 'Interpreter', 'latex'); ylabel('$y - H/N$', 'Interpreter', 'latex'); zlabel('$z - Z$', 'Interpreter', 'latex')
% subplot(1, 3, 3)
% plot(custom_AIR_fit_Z, [Bulk_AIR_FUEL(1, :)', Bulk_AIR_FUEL(12, :)'], Bulk_AIR_FUEL(40, :)'), title('Source Data')
% alpha(0.5), xlim([0, 100]), ylim([0, 8]), zlim([0, .1])
% xlabel('$x - CH_4$\%', 'Interpreter', 'latex'); ylabel('$y - H/N$', 'Interpreter', 'latex'); zlabel('$z - Z$', 'Interpreter', 'latex')



% 
% 
% % Deployment
% % See the help for each generation function for more information.
% write_model = questdlg('Would you like to write the model to a function?',...
%     'Write model to function', 'Yes', 'No', 'No');
% 
% if strcmp(write_model, 'Yes')
%     % Generate MATLAB function for neural network for application
%     % deployment in MATLAB scripts or with MATLAB Compiler and Builder
%     % tools, or simply to examine the calculations your trained neural
%     % network performs.
%     function_name = inputdlg('Write below the NN model function name:', 'Function Name');
%     genFunction(net, function_name);
% %     y = LIBS_Calibration_NNFunction(x);
% end
% if (false)
%     % Generate a matrix-only MATLAB function for neural network code
%     % generation with MATLAB Coder tools.
%     genFunction(net,'myNeuralNetworkFunction','MatrixOnly','yes');
%     y = myNeuralNetworkFunction(x);
% end
% if (false)
%     % Generate a Simulink diagram for simulation or deployment with.
%     % Simulink Coder tools.
%     gensim(net);
% end




